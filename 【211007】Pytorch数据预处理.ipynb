{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch 数据预处理与数据集加载\n",
    "October 7, 2021\n",
    "***\n",
    "在Pytorch构建神经网络对数据集进行训练和测试前，需要对数据进行预处理操作。预处理的主要任务就是将图片、文字、视频等形式的训练/测试集转换为Python能够读取的数据。具体地，需要将这些数据转换为张量(tensor)  \n",
    "在Pytorch框架中，对于数据的预处理具有严格的程序规范。包括**创建对象**,**说明方法**等。 \n",
    "\n",
    "这部分内容主要举一些例子，并结合代码，详细说明Pytorch的数据预处理."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.概述\n",
    "Pytorch的数据预处理可以概括为“三步走”  \n",
    "+ 创建Dataset类 - 将**普通的数据**变成**Pytorch认识的数据集**  \n",
    "+ 创建Dataloader类 - 对数据进行“斗地主中”**洗牌**,**发牌**等操作（对应Shuffle,Batch）\n",
    "+ 转换Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Dataset类与数据集读取\n",
    "Dataset类是将**普通的数据**转换为**Pytorch认识的数据**的一个类\n",
    "## 1.1 数据集及其格式\n",
    "一般情况下，一个完整的数据集应该由以下两部分组成\n",
    "+ 数据 （如文字，图像，视频序列）\n",
    "+ 标签 （如类别，像素位置等）  \n",
    "数据集中的数据形式，随着不同数据集的变化各不相同,在使用时需要根据指定的格式进行预处理  \n",
    "下面举几个例子，说明一般数据集具有的数据结构特点： \n",
    "\n",
    "### CIFAR10数据集  \n",
    "CIFAR10数据集包含60000张32×32大小的图像，这些图像来自10个常见物品（如飞机、汽车、鸟、狗等）\n",
    "<img src=\"https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fyqfile.alicdn.com%2F8fe03194fc0933b8ed08fcfbfcca2bdc44201da7.png&refer=http%3A%2F%2Fyqfile.alicdn.com&app=2002&size=f9999,10000&q=a80&n=0&g=0n&fmt=jpeg?sec=1636166953&t=52a168c83244bf9191d820dfafdeddb2\">\n",
    "\n",
    "+ 数据：像素数据(0 ~ 255,三通道)使用numpy数组存储。32×32大小，10000张图，共形成10000×3072的numpy数组，存整形变量\n",
    "+ 标签：标签数据(0 ~ 9),形成列表list。分别表示训练数据所对应的类别\n",
    "\n",
    "\n",
    "### MNIST手写数字识别数据集\n",
    "MNIST手写数字识别数据集包含60000张训练集以及10000张测试集，这些图像来自10个手写数字\n",
    "<img src=\"https://img2.baidu.com/it/u=2939531682,1020933556&fm=26&fmt=auto\">\n",
    "MNIST数据集官网并不直接提供手写数字的图像文件(.img等格式)。而是将他们在内存中的地址关系以及地址单元中的内容进行存储，需要写程序将MNIST读取。存取规则如下：  \n",
    "+ 数据：像素数据(0 ~ 255)使用一个字节地址存储，体现在图像上为**黑白图片**  \n",
    "+ 标签：标签数据(0 ~ 9)使用一个字节地址存储\n",
    "\n",
    "\n",
    "### 中文文本分类数据集\n",
    "<img src=\"./截屏2021-10-07 15.23.55.png\">  \n",
    "+ 数据：如图所示，数据为文字数据，每一行为一个数据，行内使用 \" _ ! _ \" 区分  \n",
    "+ 标签：分别表示新闻ID,分类Code，分类名称，新闻字符串，新闻关键词\n",
    "\n",
    "\n",
    "### 人体姿态识别数据集\n",
    "<img src=\"http://sam.johnson.io/research/images/dataset_et/im00004.jpg\"> <img src=\"http://sam.johnson.io/research/images/dataset_et/viz/im00004.jpg\" width=20% height=20%>\n",
    "+ 数据：以图片(im000x.jpg)格式给出，共2000张图，每张\n",
    "+ 标签：以表格(joints.mat)格式给出，大小为3×14×2000，存每个图像14个关键点的坐标位置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 自建数据集\n",
    "然而，在大多数场景下，无法使用Pytorch可以直接支持的数据集进行操作。因此需要根据一定格式，创建易于读取的数据集。  \n",
    "在创建数据集的过程中，所有数据需要保证在一个文件夹中。  \n",
    "注意：在任何系统中，`~/`符号表示系统主目录，而`./`表示当前文件所在的根目录，用于表示**相对路径**  \n",
    "以人脸姿态数据集为例，假设数据存放的相对路径`./faces`为保证程序正常运行，该目录下应包含：\n",
    "+ 数据：以图片形式给出：`ABC.jpg`等\n",
    "+ 标签：以`data.csv`形式给出，形式如下:  \n",
    "\n",
    "| 图片文件名    | 标签 |\n",
    "| ----------- | ----------- |\n",
    "| ABC.jpg     | 1       |\n",
    "| BCD.jpg     | 2        |\n",
    "\n",
    "具体地，由于数据中，每个点包含的标签信息不再是**类别信息**，而是14个关键点的(x,y)坐标，故`data.csv`中具体格式应当为  \n",
    "\n",
    "| **图片文件名**             | **part0_x** | **part0_y** | **part1_x** | **part1_y** | **.......** | **part67_y** |\n",
    "|-----------------------|-------------|-------------|-------------|-------------|-------------|--------------|\n",
    "| `0805personalli01\\.jpg` | 27          | 83          | 27          | 98          |             |              |\n",
    "| `1084\\.\\.\\.\\.jpg `      | 70          | 236         | 71          | 257         |             |              |\n",
    "| \\.\\.\\.\\.              |             |             |             |             |             |              |\n",
    "\n",
    "接着，开始读取数据集中的数据和标签。在代码中输入以下内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.transforms import ToPILImage\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 在成功引入以下包后，在上一个文本框中的 `In [ ]:` 可以正常显示数字  \n",
    " 接着，输入如下代码，读取表格中的文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('./faces/face_landmarks.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取成功后，查看label的类型,输入`type(labels)`，应显示`pandas.core.frame.DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接着，对`.csv`格式文件进行读取，以第1行数据为例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "image_name = labels.iloc[n,0]\n",
    "image_mark = labels.iloc[n,1:]\n",
    "image_mark = np.asarray(image_mark)\n",
    "image_mark = image_mark.astype('int').reshape(-1,2)\n",
    "\n",
    "#print(image_name)\n",
    "#print(image_mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取成功后，若可以查看输出的表格信息，则说明`.csv`格式文件成功读取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Dataset类\n",
    "在Pytorch中，用于生成数据集的类继承Dataset父类。以便将数据集转换成Pytorch可以识别的形式。  \n",
    "其中，常见数据集可以直接表示为Dataset类，无需手动生成。这样的数据集包括\n",
    "+ MNIST\n",
    "+ COCO\n",
    "+ Captions\n",
    "+ Detection\n",
    "+ LSUN\n",
    "+ ImageFolder\n",
    "+ Imagenet-12\n",
    "+ CIFAR\n",
    "+ STL10\n",
    "+ SVHN\n",
    "+ PhotoTour\n",
    "\n",
    "> PyTorch domain libraries provide a number of pre-loaded datasets (such as FashionMNIST) that subclass torch.utils.data.Dataset and implement functions specific to the particular data. They can be used to prototype and benchmark your model. \n",
    "https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "\n",
    "将读取文件并构造数据集的方法封装成一个类。该类需要继承`Dataset`父类，又要包含以下方法\n",
    "+ `__len__`  定义获取数据集的总长度，使用`len(object_name)`获取\n",
    "+ `__getitem__` 定义获取数据的方法，即使用`[]`索引访问  \n",
    "\n",
    "### 下面以`某人脸数据集`为例，说明Pytorch不认识数据集的构建方法\n",
    "参考代码如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceLabelDataset(Dataset):\n",
    "    def __init__(self,csv,img_path):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        csv(string):Path to the csv file with labels\n",
    "        img_path(string):Path to the image folder\n",
    "        \"\"\"\n",
    "        self.labels = pd.read_csv(csv)\n",
    "        self.img_path = img_path\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        a = self.labels.iloc[idx,1:]\n",
    "        a = np.array([a])\n",
    "        a = a.reshape(-1,2)\n",
    "        return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将`FaceLabelDataset`例化，生成实体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = FaceLabelDataset('./faces/face_landmarks.csv','./faces/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([73, 220], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd[3][4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下面以`MNIST`数据集为例，说明Pytorch认识数据集的构建方法\n",
    "以 MNIST为例，这部分数据集直接在Pytorch中为封装好的Dataset类，直接引用代码如下  \n",
    "**请注意：在运行该代码前，需要保证import部分已经运行，否则将无法使用torchvision等包**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST(root='./MNIST_pytorch/',train=True,transform=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "若提示未下载，在argument中加入 `download=True` 声明即可  \n",
    "对数据集进行索引，输入如下代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.train_labels[1344]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0 - zero',\n",
       " '1 - one',\n",
       " '2 - two',\n",
       " '3 - three',\n",
       " '4 - four',\n",
       " '5 - five',\n",
       " '6 - six',\n",
       " '7 - seven',\n",
       " '8 - eight',\n",
       " '9 - nine']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  41, 111, 232, 196,\n",
       "          74,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   1,  40, 161, 242, 254, 254, 253,\n",
       "         252, 210, 204,  37,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,  13, 223, 254, 254, 254, 167,  72,\n",
       "          73, 168, 254, 195,  19,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   6, 157, 254, 181,  35,  35,   8,   0,\n",
       "           0,   9, 173, 254, 117,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,  66, 254, 254,  56,   0,   0,   0,   0,\n",
       "           0,   0, 116, 254, 129,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   7, 224, 254, 127,   0,   0,   0,   0,\n",
       "           0,   0, 128, 254, 118,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0, 115, 254, 246,  85,   0,   0,   0,\n",
       "           0,   0, 215, 231,  20,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   2, 113, 235, 250, 169,  41,   1,\n",
       "           0, 113, 252, 168,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  93, 254, 254, 254, 196,\n",
       "         117, 233, 249,  53,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,  38, 159, 243, 254,\n",
       "         254, 254, 141,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  38, 212,\n",
       "         254, 254, 232, 111,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  23, 251,\n",
       "         230, 208, 254, 254, 198,  18,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3, 144, 252,\n",
       "          62,  10,  85, 210, 254, 227,  23,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 135, 254, 149,\n",
       "           0,   0,   0,  24, 207, 254, 147,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  76, 253, 170,   1,\n",
       "           0,   0,   0,   0,  37, 254, 219,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  86, 254,  89,   0,\n",
       "           0,   0,   0,   0,  57, 254, 148,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 125, 217,   5,   0,\n",
       "           0,   0,   0,  10, 182, 254,  67,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 160, 214,   0,   0,\n",
       "           0,   0,  41, 135, 254, 226,  13,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 128, 253, 206,  88,\n",
       "          69, 169, 250, 254, 222,  36,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  19, 204, 254, 254,\n",
       "         194, 254, 209, 127,  28,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
       "       dtype=torch.uint8)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = train.train_data[1344]\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对数据可视化，正确结果应当弹出一张图片，显示数字`8`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorImageShow(tensorin):\n",
    "    show = ToPILImage()\n",
    "    show(tensorin).show()\n",
    "\n",
    "tensorImageShow(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.DataLoader类与数据集基本操作\n",
    "DataLoader类是接续Dataset类后，为了完成数据集进行进一步操作，如**分批 - batch_size, 洗牌 - shuffle**等\n",
    "\n",
    "  以例化的人脸数据集`fd`为例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdl = torch.utils.data.DataLoader(fd,batch_size=5,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参考\n",
    "### Pytorch 数据预处理过程\n",
    "+ https://zhuanlan.zhihu.com/p/173727709\n",
    "+ https://zhuanlan.zhihu.com/p/95504432\n",
    "+ https://blog.csdn.net/kdongyi/article/details/103272579\n",
    "\n",
    "### 数据集官方说明\n",
    "+ https://www.cs.toronto.edu/~kriz/cifar.html CIFAR数据集\n",
    "+ http://yann.lecun.com/exdb/mnist/ MNIST数据集\n",
    "+ https://www.kaggle.com/sinakaraji/covid-vaccination-vs-death/version/1 covid19病例数据集\n",
    "+ https://github.com/aceimnorstuvwxz/toutiao-text-classfication-dataset 今日头条新闻标题分类数据集\n",
    "+ http://sam.johnson.io/research/lsp.html 人体姿态识别数据集\n",
    "\n",
    "### 数据集处理教程参考\n",
    "+ https://www.jianshu.com/p/e7c286530ab9 MNIST数据集的处理\n",
    "+ https://zhuanlan.zhihu.com/p/130673468 Pytorch加载自己的数据集\n",
    "+ https://blog.csdn.net/qq_32896115/article/details/90311697 MNIST与自建数据集处理方法的比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
